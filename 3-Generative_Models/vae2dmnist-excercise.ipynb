{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Variational autoencoder"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Auto-Encoding Variational Bayes (Kingma, Welling, 2013)](https://arxiv.org/abs/1312.6114)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "id": "K__ySwAGTwtA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the MNIST dataset in the same way as for the perceptron."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "\nplt.imshow(np.reshape(-mnist.train.images[4242], (28, 28)), interpolation='none');"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<matplotlib.figure.Figure at 0x10a196f28>"
            ],
            "image/png": [
              "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
              "AAALEgAACxIB0t1+/AAADctJREFUeJzt3XuMXGUZx/Hf020pUorSC81at1ZCAykYWjNUExpFBSlI\n",
              "UoyxQiIWJRZvxAsaETVi4h9ExUuMoos0FMNFIyJNJBJo1MZwaZdaeqEIFYrtWrqlrdIKtOz28Y89\n",
              "6FJ23pnOnDPnlOf7STY7c54z5zyZ9rfnzLxn5jV3F4B4xpTdAIByEH4gKMIPBEX4gaAIPxAU4QeC\n",
              "IvxAUIQfCIrwA0GN7eTOpkzq8pk94zq5SyCULVtf0rO7h6yZddsKv5ktkPQjSV2SfuHu16bWn9kz\n",
              "Tqvu6WlnlwAS5p27tel1Wz7tN7MuST+RdJ6k2ZIuNrPZrW4PQGe185p/nqTN7v6kux+QdLukhfm0\n",
              "BaBo7YR/uqSR5xjbsmWvYGZLzKzPzPp27hpqY3cA8lT4u/3u3uvuNXevTZ3cVfTuADSpnfD3Sxr5\n",
              "7t2bsmUAjgDthH+1pFlm9hYzO0rSRZKW59MWgKK1PNTn7oNm9llJ92h4qG+pu2/MrTMAhWprnN/d\n",
              "75Z0d069AOggLu8FgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAo\n",
              "wg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4g\n",
              "qLZm6TWzLZL2ShqSNOjutTyaAlC8tsKfebe7P5vDdgB0EKf9QFDtht8l3WdmD5vZkjwaAtAZ7Z72\n",
              "z3f3fjM7QdK9ZvaYu68cuUL2R2GJJM2YnserDAB5aOvI7+792e8BSXdKmjfKOr3uXnP32tTJXe3s\n",
              "DkCOWg6/mU0ws4kv35b0Pkkb8moMQLHaOQ+fJulOM3t5O7e6+x9y6QpA4VoOv7s/Ken0HHsB0EEM\n",
              "9QFBEX4gKMIPBEX4gaAIPxAU4QeC4nrb14C1+/fXrd313NzkY393w1nJ+pgDnt65pctJDTa9rydd\n",
              "v3fxd5P1GWOPPcyGYuHIDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBMc5/BJj9k08n69P//Hzd2pj7\n",
              "1ycfe4IeSu/cD6brVtzxY0qD+kfv/0Ky/skf/qZu7aKJe1ro6LWFIz8QFOEHgiL8QFCEHwiK8ANB\n",
              "EX4gKMIPBMU4fwWcvuriZH3mzx5L1of2/DvPdo4Y4+9Zk6xv3j+tfpFxfo78QFSEHwiK8ANBEX4g\n",
              "KMIPBEX4gaAIPxBUw3F+M1sq6QJJA+5+WrZskqRfSZopaYukRe7OwGmL3nDjxGR9aM/jLW/b5p6S\n",
              "rA+ccVz68Q2+W98bfG//Ufvqb+D1t65OPxiFaubIf5OkBYcsu0rSCnefJWlFdh/AEaRh+N19paTd\n",
              "hyxeKGlZdnuZpAtz7gtAwVp9zT/N3bdnt5+RlLiOEkAVtf2Gn7u7ErOumdkSM+szs76du4ba3R2A\n",
              "nLQa/h1m1i1J2e+Beiu6e6+719y9NnVyV4u7A5C3VsO/XNLi7PZiSXfl0w6ATmkYfjO7TdIDkk42\n",
              "s21mdpmkayWdY2ZPSDo7uw/gCNJwnN/d633Y/L059xLWP85rsMIFb0uWv/WuO+vWThn/YPKx88aP\n",
              "a7Dz9vz74At1a+d6+nv3X38b1wEUiSv8gKAIPxAU4QeCIvxAUIQfCIrwA0Hx1d0V8NSFvQVuvdih\n",
              "vEb+OVj/I73H9h/oYCc4FEd+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcX605R+D+5L1T32q/sd2\n",
              "x69MT7HdyN5FZyTrX57840S13OsfqoAjPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ExTh/DgaG/pOs\n",
              "/+dgep7rs1dekayf8o1dyfrg01uT9XbsX1BL1sf/oS9dV6Lu6eel69STk/Wvffum9L6NsfwUjvxA\n",
              "UIQfCIrwA0ERfiAowg8ERfiBoAg/EFTDcX4zWyrpAkkD7n5atuwaSZ+QtDNb7Wp3v7uoJjthv7+U\n",
              "rPf+66S6td9/ZH7ysf7IY8n6SVqXrA8mq5KsuL/hjcbx29q3pcvPzzguWZ9g6e/933ig/vTgpx71\n",
              "uvTOA2jmX+4mSQtGWf4Dd5+T/RzRwQciahh+d18paXcHegHQQe2cL15hZuvMbKmZHZ9bRwA6otXw\n",
              "Xy/pRElzJG2XdF29Fc1siZn1mVnfzl1DLe4OQN5aCr+773D3IXc/KOkGSfMS6/a6e83da1Mnd7Xa\n",
              "J4CctRR+M+secfcDkjbk0w6ATmlmqO82SWdJmmJm2yR9U9JZZjZHkkvaIunyAnsEUADzBp+pzlPt\n",
              "9KN91T09HdvfSH96IX2S88Xvpf9+Tf35qjzbOSxju6cl64PbdxS3cz+Yrhd4jUG7xpw2q26t/5xJ\n",
              "he573ZU/LXT79cw7d6v6HnmxwRUUw6r7LwegUIQfCIrwA0ERfiAowg8ERfiBoMJ8dfcV138yWX/j\n",
              "zx/qUCeHb7BnSnqFAof6ht41N1m3wfRQ4Jj71+fZzmE5uOGJurXuBpeljZ0xPVkf6n8mvYEr0+Uq\n",
              "4MgPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GFGed/43UPpFeo8EdTtWpjsjx2Zv2PSW/+WHfdmiSd\n",
              "/M6nkvXls5Ym63uGnk/W37Pm43VrE5c2+Gruvz+XrDey+SP1v1qy+4H0V8rNv+bBZP3xfSe01FOV\n",
              "VPh/PIAiEX4gKMIPBEX4gaAIPxAU4QeCIvxAUGHG+Tdf9/Zk/aQvrW5524NnzUnWh8an/8ZO2JT+\n",
              "PP7my9KfLf/qh+6oW7v0uIHkY9t1fNcxyfpfz7i9fvGM9LZ///zRLXT0f+8/5sX6xY+2tWkp/W3q\n",
              "RwSO/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVMNxfjPrkXSzhkc2XVKvu//IzCZJ+pWkmZK2SFrk\n",
              "7nuKa7U9j374x8n6d89+a8vb/uBx6W1PGJP+bvv7X0hPW37RxMo+rYVKjtOjbc0c+QclXenusyW9\n",
              "Q9JnzGy2pKskrXD3WZJWZPcBHCEaht/dt7v7muz2XkmbJE2XtFDSsmy1ZZIuLKpJAPk7rNf8ZjZT\n",
              "0lxJD0ma5u7bs9Izek1c8AjE0XT4zexYSXdI+ry7v+LL1dzdNfx+wGiPW2JmfWbWt3NX+nvTAHRO\n",
              "U+E3s3EaDv4t7v7bbPEOM+vO6t2SRv0Eibv3unvN3WtTJ3fl0TOAHDQMv5mZpBslbXL3748oLZe0\n",
              "OLu9WNJd+bcHoCjNfKT3TEmXSFpvZmuzZVdLulbSr83sMklPS1pUTIv5GG/jkvWvT3msja2nP9ba\n",
              "yIygQ3koV8Pwu/tfJFmd8nvzbQdAp3CFHxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTh\n",
              "B4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU\n",
              "4QeCIvxAUIQfCIrwA0ERfiCohuE3sx4z+6OZPWpmG83sc9nya8ys38zWZj/nF98ugLyMbWKdQUlX\n",
              "uvsaM5so6WEzuzer/cDdv1dcewCK0jD87r5d0vbs9l4z2yRpetGNASjWYb3mN7OZkuZKeihbdIWZ\n",
              "rTOzpWZ2fJ3HLDGzPjPr27lrqK1mAeSn6fCb2bGS7pD0eXd/TtL1kk6UNEfDZwbXjfY4d+9195q7\n",
              "16ZO7sqhZQB5aCr8ZjZOw8G/xd1/K0nuvsPdh9z9oKQbJM0rrk0AeWvm3X6TdKOkTe7+/RHLu0es\n",
              "9gFJG/JvD0BRmnm3/0xJl0hab2Zrs2VXS7rYzOZIcklbJF1eSIcACtHMu/1/kWSjlO7Ovx0AncIV\n",
              "fkBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaDM3Tu3M7Od\n",
              "kp4esWiKpGc71sDhqWpvVe1LordW5dnbm919ajMrdjT8r9q5WZ+710prIKGqvVW1L4neWlVWb5z2\n",
              "A0ERfiCossPfW/L+U6raW1X7kuitVaX0VuprfgDlKfvID6AkpYTfzBaY2d/MbLOZXVVGD/WY2RYz\n",
              "W5/NPNxXci9LzWzAzDaMWDbJzO41syey36NOk1ZSb5WYuTkxs3Spz13VZrzu+Gm/mXVJelzSOZK2\n",
              "SVot6WJ3f7SjjdRhZlsk1dy99DFhM3unpH2Sbnb307Jl35G0292vzf5wHu/uX6lIb9dI2lf2zM3Z\n",
              "hDLdI2eWlnShpEtV4nOX6GuRSnjeyjjyz5O02d2fdPcDkm6XtLCEPirP3VdK2n3I4oWSlmW3l2n4\n",
              "P0/H1emtEtx9u7uvyW7vlfTyzNKlPneJvkpRRvinS9o64v42VWvKb5d0n5k9bGZLym5mFNOyadMl\n",
              "6RlJ08psZhQNZ27upENmlq7Mc9fKjNd54w2/V5vv7nMknSfpM9npbSX58Gu2Kg3XNDVzc6eMMrP0\n",
              "/5T53LU643Xeygh/v6SeEffflC2rBHfvz34PSLpT1Zt9eMfLk6RmvwdK7ud/qjRz82gzS6sCz12V\n",
              "ZrwuI/yrJc0ys7eY2VGSLpK0vIQ+XsXMJmRvxMjMJkh6n6o3+/BySYuz24sl3VViL69QlZmb680s\n",
              "rZKfu8rNeO3uHf+RdL6G3/H/u6SvldFDnb5OlPRI9rOx7N4k3abh08CXNPzeyGWSJktaIekJSfdJ\n",
              "mlSh3n4pab2kdRoOWndJvc3X8Cn9Oklrs5/zy37uEn2V8rxxhR8QFG/4AUERfiAowg8ERfiBoAg/\n",
              "EBThB4Ii/EBQhB8I6r9i+Smv0HfcswAAAABJRU5ErkJggg==\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "id": "Ba6opXJcTwtN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 3
            },
            {
              "item_id": 4
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "382d639b-4020-4dd3-cb9d-be167b0a384c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1510921011250,
          "user_tz": -60,
          "elapsed": 1143,
          "user": {
            "displayName": "David Nagy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116820342271745675144"
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "XXLxdpyUTwtW",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a placeholder called `x` for data minibatches of size 64. Then create two fully connected layers in the same way as for the classifier, but here with softplus nonlinearities instead of sigmoids (`tf.nn.softplus`). The last layer should map with a linear trainsformation into the parameters of the gaussian posterior. These should for now be two n_z dimensional vector variables named `z_mean` and `z_log_sigma_sq`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "n_z = 2 #Dimension of the latent space\n",
        "batch_size = 64"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now define the sampling from the variational posterior, where we need to generate z samples for the whole minibatch."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "eps = tf.random_normal((batch_size, n_z), 0, 1, dtype=tf.float32) # Adding a random number\n",
        "z = tf.add(z_mean, tf.multiply(tf.sqrt(tf.exp(z_log_sigma_sq)), eps))  # The sampled z"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "id": "_WHGDYExTwta",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "ONyo-8ZATwtZ",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generative model or decoder takes the latent $z$ values as inputs and generates datapoints from them. Define a two-layer fully connected network again to use as a generative model of digits. The last layer should map linearly into a vector of mean pixel values named `x_reconstr_mean`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function"
      ],
      "metadata": {
        "id": "kmPvT_ZeTwte",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ELBO loss consists of the reconstruction and regularization terms. The first is the expected value of the log pdf of data conditioned on the inferred z value, the second is the kl divergence between the inferred posterior and the prior. The KL term can be calculated analytically for the case where both the prior and the posterior are gaussians."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "id": "x5QNNBwBTwtf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "QdC1s3eCTwti",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs = 10 #Set to 0, for no training\n",
        "n_samples = mnist.train.num_examples\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    batch_xs, _ = mnist.train.next_batch(batch_size)\n",
        "    print(batch_xs.shape)\n",
        "    dd = sess.run([cost], feed_dict={x: batch_xs})\n",
        "    print('Test run after starting {}'.format(dd))\n",
        "\n",
        "    for epoch in range(runs):\n",
        "        avg_cost = 0.\n",
        "        total_batch = int(n_samples / batch_size)\n",
        "        # Loop over all batches\n",
        "        for i in range(total_batch):\n",
        "            batch_xs, _ = mnist.train.next_batch(batch_size)\n",
        "            _,d = sess.run((optimizer, cost), feed_dict={x: batch_xs})\n",
        "            avg_cost += d / n_samples * batch_size\n",
        "\n",
        "        # Display logs per epoch step\n",
        "        if epoch % 1 == 0:\n",
        "            save_path = saver.save(sess, \"./model.ckpt\") #Saves the weights (not the graph)\n",
        "            print(\"Model saved in file: {}\".format(save_path))\n",
        "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and analyse model"
      ],
      "metadata": {
        "id": "u5G7heLTTwtm",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_point_file = \"./model.ckpt\""
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "id": "xbp19H5yTwtn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, check_point_file)\n",
        "    print(\"Model restored.\")\n",
        "    x_sample = mnist.test.next_batch(64)[0]\n",
        "    x_reconstruct,z_vals,z_mean_val,z_log_sigma_sq_val  = sess.run((x_reconstr_mean,z, z_mean, z_log_sigma_sq), feed_dict={x: x_sample})\n",
        "\n",
        "    plt.figure(figsize=(8, 12))\n",
        "    for i in range(5):\n",
        "        plt.subplot(5, 3, 3*i + 1)\n",
        "        plt.imshow(x_sample[i].reshape(28, 28), vmin=0, vmax=1,  interpolation='none',cmap=plt.get_cmap('gray'))\n",
        "        plt.title(\"Test input\")\n",
        "        \n",
        "        #plt.colorbar()\n",
        "        plt.subplot(5, 3, 3*i + 2)\n",
        "        plt.scatter(z_vals[:,0],z_vals[:,1], c='gray', alpha=0.5)\n",
        "        plt.scatter(z_mean_val[i,0],z_mean_val[i,1], c='green', s=64, alpha=0.5)\n",
        "        plt.scatter(z_vals[i,0],z_vals[i,1], c='blue', s=16, alpha=0.5)\n",
        "       \n",
        "        plt.xlim((-3,3))\n",
        "        plt.ylim((-3,3))\n",
        "        plt.title(\"Latent Space\")\n",
        "        \n",
        "        plt.subplot(5, 3, 3*i + 3)\n",
        "        plt.imshow(x_reconstruct[i].reshape(28, 28), vmin=0, vmax=1, interpolation='none',cmap=plt.get_cmap('gray'))\n",
        "        plt.title(\"Reconstruction\")\n",
        "        #plt.colorbar()\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, check_point_file)\n",
        "    print(\"Model restored.\")\n",
        "    d = np.zeros([batch_size,2],dtype='float32')\n",
        "    d[0,] = [1,2]\n",
        "    x_reconstruct = sess.run(x_reconstr_mean, feed_dict={z: d})\n",
        "    plt.imshow(x_reconstruct[0].reshape(28, 28), vmin=0, vmax=1,interpolation='none',cmap=plt.get_cmap('gray'))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nx = ny = 20\n",
        "x_values = np.linspace(-3, 3, nx)\n",
        "y_values = np.linspace(-3, 3, ny)\n",
        "canvas = np.empty((28*ny, 28*nx))\n",
        "saver = tf.train.Saver()\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, check_point_file)\n",
        "    for i, yi in enumerate(x_values):\n",
        "        for j, xi in enumerate(y_values):\n",
        "            z_mu = np.array([[xi, yi]])\n",
        "            d[0] = z_mu\n",
        "            x_mean = sess.run(x_reconstr_mean, feed_dict={z: d})\n",
        "            canvas[(nx-i-1)*28:(nx-i)*28, j*28:(j+1)*28] = x_mean[0].reshape(28, 28)\n",
        "\n",
        "plt.figure(figsize=(8, 10))        \n",
        "Xi, Yi = np.meshgrid(x_values, y_values)\n",
        "plt.imshow(canvas, origin=\"upper\", vmin=0, vmax=1,interpolation='none',cmap=plt.get_cmap('gray'))\n",
        "plt.tight_layout()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver()\n",
        "all_z = np.zeros((1,2))\n",
        "all_z_vals = np.zeros((1,2))\n",
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, check_point_file)\n",
        "    total_batch = int(n_samples / batch_size)\n",
        "    # Loop over all batches\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, _ = mnist.train.next_batch(batch_size)\n",
        "        x_reconstruct,z_vals,z_mean_val,z_log_sigma_sq_val  = sess.run(\n",
        "            (x_reconstr_mean,z, z_mean, z_log_sigma_sq), feed_dict={x: batch_xs})\n",
        "        all_z = np.vstack((all_z, z_mean_val))\n",
        "        all_z_vals = np.vstack((all_z_vals, z_vals))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./model.ckpt\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "id": "Zf_RSVNGTwty",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dea32b47-ce6a-4dec-b51f-3acb009a2fe7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1510929167236,
          "user_tz": -60,
          "elapsed": 12417,
          "user": {
            "displayName": "David Nagy",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "116820342271745675144"
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(all_z[:,0], all_z[:,1], s=0.2)\n",
        "plt.xlim(-3,3)\n",
        "plt.ylim(-3,3)\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist2d(all_z[:,0], all_z[:,1], (50, 50), cmap=plt.cm.jet)\n",
        "plt.colorbar()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.close()\n",
        "plt.figure(figsize=(25,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(all_z[:,0], all_z[:,1], s=0.2)\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(all_z_vals[:,0], all_z_vals[:,1], s=0.2)\n",
        "plt.xlim(-3,3)\n",
        "plt.ylim(-3,3)"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "bPH13CcVYS1F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "vae2dmnist.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}